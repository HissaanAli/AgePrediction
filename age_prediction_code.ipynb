{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f52092-22c8-439e-8e45-652be0e30414",
   "metadata": {},
   "source": [
    "<img src = \"https://www.orientis.ai/wp-content/uploads/thegem-logos/logo_160772ad35471464576035668f215dbc_1x.png\">\n",
    "\n",
    "## ORIENTIS.AI INTERVIEW TASK\n",
    "\n",
    "`Best Test L1 Score: 5.46`\n",
    "\n",
    "\n",
    "## TABLE OF CONTENTS\n",
    "\n",
    "<ul>\n",
    "    <li><b>IMPORTS</b></li>\n",
    "    <li><b>HELPTER METHODS AND GLOBAL VARIABLES</b></li>\n",
    "    <li><b>DATA LOADER</b></li>\n",
    "    <li><b>DATA VISUALIZATION</b></li>\n",
    "    <li><b>DATA PREPARATION + DATA PRE-PROCESSING</b></li>\n",
    "    <li><b>MODEL ARCHITECTURE</b></li>\n",
    "    <li><b>MODEL CALLBACKS</b></li>\n",
    "    <li><b>MODEL TRAINING</b></li>\n",
    "    <li><b>MODEL EVALUATION</b></li>\n",
    "    <li><b>RESULTS</b></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9faa7-809f-4c48-8c36-b454da7f0b78",
   "metadata": {},
   "source": [
    "# IMPORTS\n",
    "\n",
    "At the very start of the project I am importing the necessary libraries required for this project.They would be heavily used throught the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8942ae6-73d3-4d24-a5e5-3d7bd3deb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP LEARNING MODULES\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# DATA VISUALIZATIONS MODULES\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# MACHINE LEARNING MODULES\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# DATA PRE-PROCESSING AND MANIPULATION MODULES\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random as r\n",
    "\n",
    "# IPYTHON WIDGETS\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fff321-c7d2-46fb-aa80-f9dcaece6776",
   "metadata": {},
   "source": [
    "# HELPER METHODS AND GLOBAL VARIABLES\n",
    "\n",
    "Then at the next step i am defining a few constant variables and helper methods that would be used through the project for various tasks. They are stand-alone method and need not to be associated with a particular class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9405ca-f0cc-4e58-9e8e-79fb8a1f134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 91\n",
    "IMG_HEIGHT = 91\n",
    "\n",
    "TRAIN_PATH = \"dataset/training_set/\"\n",
    "VAL_PATH = \"dataset/validation_set/\"\n",
    "TEST_PATH = \"dataset/test_set/\"\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "def gray_to_rgb(img):\n",
    "    return tf.image.grayscale_to_rgb(tf.convert_to_tensor(img.reshape(IMG_WIDTH,IMG_HEIGHT,1)))\n",
    "def resize(img):\n",
    "    return tf.image.resize(img, [224,224], method='nearest').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da83dd-a5da-40e6-80fd-892719eff3f1",
   "metadata": {},
   "source": [
    "# DATA LOADER\n",
    "\n",
    "This is the `DataLoader` part where i am importing the dataset from the local storage and populating it into pandas data frame. \n",
    "\n",
    "I have also created an `Item` class which represents an individual record. It contains the path of the image and it's output label i.e age. This item class is then used in DataLoader class which using those Item objects creates a data frame.\n",
    "\n",
    "I have also defined a method `display_stats()` which display the distribution and statistic of each data frame (training, validation, testing). This gives us a nice understanding of the data at hand. We can see that the all the 3 datasets, training, validation and test sets have <b>similar</b> statistical figures like mean, std, percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6de97-3b39-45d2-b3d5-5243d4b3a247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Item:\n",
    "    def __init__(self, path):\n",
    "        self._image = np.array(Image.open(path))\n",
    "        self._age = int(path.split('/')[-1].split('_')[0])\n",
    "    def get_image(self):\n",
    "        return self._image\n",
    "    def get_age(self):\n",
    "        return self._age\n",
    "\n",
    "class DataLoader:\n",
    "    def load_into_df(self, path):\n",
    "        data = {\n",
    "            'path': [],\n",
    "            'age': []\n",
    "               }\n",
    "        file_names = os.listdir(path)\n",
    "        for file in file_names:\n",
    "            data['age'].append(int(file.split('/')[-1].split('_')[0]))\n",
    "            data['path'].append(file)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    def display_stats(self, *dfs):\n",
    "        names = ['TRAIN', 'VALIDATION', 'TEST']\n",
    "        for df, name, in zip(dfs, names):\n",
    "            print(name)\n",
    "            display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2de444-5af3-4739-b65f-8267b225ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader()\n",
    "\n",
    "train_df = data_loader.load_into_df(TRAIN_PATH)\n",
    "val_df = data_loader.load_into_df(VAL_PATH)\n",
    "test_df = data_loader.load_into_df(TEST_PATH)\n",
    "\n",
    "data_loader.display_stats(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb44726-df69-4050-a530-7eeba026baac",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION\n",
    "\n",
    "I have used `SeaBorn` library to plot the visualizations. It plots a count plot for the given distribution of output labels (age). This would help us understand the distribution of data, the insights from the visualization would then be used in the next steps in the form of necessary measures needed to be taken to improve results and adress problems if any.\n",
    "\n",
    "Note: You can see that the dataset right now is imbalanced. Imbalanced dataset create bias towards the values that occur in abundance and the model experiences high bias problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c74a3c-dfa8-446b-908b-8a567c434cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVisualizer:\n",
    "    sns.set()\n",
    "    def draw_count_plot(self, df):\n",
    "        if type(df) != pd.core.frame.DataFrame:\n",
    "            df = pd.DataFrame(df, columns = ['age'])\n",
    "        plt.rcParams[\"figure.figsize\"] = (30,15)\n",
    "        sns.countplot(data = df, x = 'age')\n",
    "        plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "        \n",
    "DataVisualizer().draw_count_plot(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc61e1-ea8c-4fe0-b608-0421886a9670",
   "metadata": {},
   "source": [
    "# DATA PREPARATION + DATA PRE-PROCESSING\n",
    "\n",
    "After having insights of the dataset from the visualizations, it's time to move on towards the data pre-processing. This steps is necessary for every machine learning models. We can not expect to thrown in bunch of data into the model and expect it to give us good results. \n",
    "\n",
    "We have to apply some pre-processing techniques that would help us get even better results. The pre-processing steps applied for this project include:\n",
    "\n",
    "<ul>\n",
    "    <li> Normalizing the inputs features that would help us the deep learning model converge faster and avoid spikes in the loss function.</li>\n",
    " \n",
    "    <li> Over sampling the dataset using Synthetic Minority Over Sampling TEchnique (<b>SMOTE</b>) to remove imbalance from the dataset and reduce bias towards abundantly occuring values.</li>\n",
    "</ul>\n",
    "    \n",
    "<b>Before Normalization</b>:\n",
    "\n",
    "<img src = 'Images/1.jpg'>\n",
    "<b>After Normalization</b>: \n",
    "<img src = 'Images/2.jpg'>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc79dcf-8905-4b28-9a6a-ca95c17bc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def get_xy(self, path, flattened = True):\n",
    "        file_names = os.listdir(path)\n",
    "        items = []\n",
    "        for file in file_names:\n",
    "            item = Item(path+file)\n",
    "            items.append(item)\n",
    "        \n",
    "        if flattened:\n",
    "            x = np.array([item.get_image().flatten() for item in items])\n",
    "        else:\n",
    "            x = np.array([item.get_image().reshape(91, 91, 1) for item in items])\n",
    "        y = np.array([item.get_age() for item in items])\n",
    "        return self.normalize(x), y\n",
    "    def normalize(self, arr):\n",
    "        return arr/255.0\n",
    "    def oversample(self, x, y):\n",
    "        smote = SMOTE(random_state=42, k_neighbors = 4)\n",
    "        x_sampled, y_sampled = smote.fit_resample(x, y)\n",
    "        x_sampled = np.array([x.reshape(-1,1).reshape(91,91, 1) for x in x_sampled])\n",
    "        return x_sampled, y_sampled\n",
    "    def show_sample(self, x):\n",
    "        index = r.randint(1, len(x)-1)\n",
    "        print('index', index)\n",
    "        plt.imshow(x[index], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6c742-a25f-40f3-a418-9cdd7b33da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processor = PreProcessor()\n",
    "\n",
    "# TRAIN-VALIDATION-TEST ARRAYS\n",
    "x_train, y_train = pre_processor.get_xy(TRAIN_PATH)\n",
    "x_val, y_val = pre_processor.get_xy(VAL_PATH)\n",
    "x_test, y_test = pre_processor.get_xy(TEST_PATH, flattened = False)\n",
    "\n",
    "# OVER SAMPLING DATA WITH SMOTE\n",
    "x_train_val, y_train_val = np.concatenate([x_train, x_val], axis = 0), np.concatenate([y_train, y_val], axis = 0)\n",
    "x_sampled, y_sampled = pre_processor.oversample(x_train_val, y_train_val)\n",
    "\n",
    "# DISPLAYING SHAPE\n",
    "print(x_sampled.shape, y_sampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64890e2f-6c00-42a0-a358-42350f4a9545",
   "metadata": {},
   "source": [
    "\n",
    "### Note:\n",
    "After using `SMOTE` to oversample the data, you can see that now the visualizations look beautiful and properly balanced. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4489e-4282-4f54-babd-6693f9457f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataVisualizer().draw_count_plot(y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6a40e-740e-42f6-a238-689cba6a8020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_processor.show_sample(x_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1799952-0ac6-40fc-8dde-8d864ca0fb3d",
   "metadata": {},
   "source": [
    "# MODEL ARCHITECTURE\n",
    "Following is the summary of the architecture of the model I have used for this project. \n",
    "\n",
    "  \n",
    "• It is  `37` layer deep model with total `525441` trainable parameters. It's a deep convolutional neural network and designed to work for the dataset at hand. \n",
    "\n",
    "• It follows the following pattern `Conv2D -> BatchNormalization -> Pooling -> Dropout` . \n",
    "\n",
    "• The `Convolution` layers are used to extract features out of the image by applying various filters that reduce the loss function. \n",
    "\n",
    "• The `MaxPooling` layers with a stride of 2 help to compress the features extracted. \n",
    "\n",
    "• The `Batch Nomralization` layers are used to introduce internal normalization into the parameters and reduce `covariate shift` during the training. \n",
    "\n",
    "• The `DropOut` layers are used to reduce over-fitting by randomly shutting down connections.\n",
    "\n",
    "• Then after some group of `Conv2D -> BatchNormalization -> Pooling -> Dropout` layers, the model was `flattened` and passed onto dense layers.\n",
    "\n",
    "• The `Dense` layers are the fully connected layers which take the compressed feature vector and use deep learning to find the best set of parameters that give the minimum loss.\n",
    "\n",
    "• Finally, since it is a `Regression` task a `1` neuron dense layer was put at the end with `linear` activation to get the age value. We didn't use other activations that give values between 0-1 probability range because then it would have turned into a classication problem . \n",
    "\n",
    "\n",
    "<img src = 'model.png'>\n",
    "# HYPER PARAMETER TUNING\n",
    "\n",
    "• A combination of `Grid Search` and `Heuristic Search` methods were used to tune the architecture. \n",
    "\n",
    "• I red a number of research papers and articles online which combined my with my experience of deep learning and CNN allowed me developed an intution of hyper parameters and it's effect on the over all model. After understanding the dynamics of the model i based on the intuition i developed tuned the model. The changes turned out to be pretty great and the model kept on improving. Each and every step along with it's loss score is recorded in the github repository.\n",
    "\n",
    "• I made sure to avoid all known major problems like OverFitting, UnderFitting, GradientVanishing, CovarianceShift, etc by employing the solutions and best practices.\n",
    "\n",
    "• `ReLu` activation function was used as it removes the vanishing gradient problem compared to sigmoid function.\n",
    "\n",
    "• `MAE` (Mean Absolute Error) was used as evaluation metrics for this project for two reasons: \n",
    "\n",
    "1. It was requirement of the task\n",
    "\n",
    "2. It is less sensitive to outliers compared to `MSE` (Mean Squared Error) which explodes to high values for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d5371-128f-4a95-9caf-192868f4183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKModel():\n",
    "   \n",
    "    def make_hidden_layers(self, inputs):\n",
    "        \"\"\"\n",
    "        STUCTURE OF NEURAL ARCHITECTURE:\n",
    "        \n",
    "        Conv2D -> BatchNormalization -> Pooling -> Dropout\n",
    "        \"\"\"\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(inputs)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.20)(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def make_fully_connected_layers(self, inputs):   \n",
    "        \"\"\"\n",
    "        Dense -> BN -> Dropout  x 3 -> Linear\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.make_hidden_layers(inputs)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        \n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def assemble_full_model(self, width, height):\n",
    "        \"\"\"\n",
    "        Assemble the INPUT LAYERS -> HIDDEN LAYERS -> OUTPUT LAYERS\n",
    "        \"\"\"\n",
    "        input_shape = (height, width, 1)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        output = self.make_fully_connected_layers(inputs)\n",
    "        \n",
    "\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = [output],\n",
    "                     name=\"face_net\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "model = UTKModel().assemble_full_model(IMG_WIDTH, IMG_WIDTH)\n",
    "\n",
    "# MODEL PARAMS\n",
    "\n",
    "init_lr = 1.2e-4\n",
    "epochs = 200\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=opt, \n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dccfca-3584-48b2-87cd-e9b81544ce20",
   "metadata": {},
   "source": [
    "# MODEL CALLBACKS\n",
    "I used a 3 of callbacks in this project. A callback is a powerful tool to customize the behavior of a tensorflow model during training, evaluation, or inference\n",
    "\n",
    "• The first callback was `PlotLearning`. This custom implemented callback allows us to visually see the graph of training vs validation loss while the data is still training. With this callback we don't have to wait for the end to see the graph of the loss function, instead now we can see it after every epoch.\n",
    "\n",
    "• The second callback was `SaveBestModel`. This custom implemented callback allows us to save only that model which has the best (minimum) validation loss. This way we don't have to worry about making the layer the deeper or increasing the epochs since in the end we would get the model with the best validation loss.\n",
    "\n",
    "• The third callback was `CheckPoint`. This default provided callback allows us to save the best performing model on to the hard-drive with all its weightss. This way we can load the best performing model anytime we want and we won't have to train it every time. It saves the model in h5 format.\n",
    "\n",
    "• I have also used `DataAugmentation` which helped us create more samples and reduce over fitting even further. \n",
    "\n",
    "### Note:\n",
    "It's important to tell you that the i have only used a few data augmentation parameters and ignored others. This is because since they were very small images (only 91 x 91). using horizontal shift, vertical shift, rotation etc, etc did more harm than good. Reasonable amount of data was removed or filled-in which didn't proove fruitful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305e63d-9ac7-4447-8dc0-4768993f7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, y, zoom_range = 0.05, horizontal_flip = True, vertical_flip = False):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          zoom_range=zoom_range,\n",
    "          horizontal_flip=horizontal_flip,\n",
    "          vertical_flip=vertical_flip,\n",
    "          fill_mode='nearest')\n",
    "    train_generator = train_datagen.flow(\n",
    "        x_sampled,\n",
    "        y_sampled,\n",
    "        batch_size=16)\n",
    "    return train_generator\n",
    "\n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights= self.model.get_weights()\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('final_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [PlotLearning(), SaveBestModel(), checkpoint]\n",
    "train_generator = augment(x_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd44cc-22dc-4a57-b0cb-395df18c1a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to load models for prediction\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6e990-87dc-464b-9d5c-fa4e63379257",
   "metadata": {},
   "source": [
    "# MODEL TRAINING\n",
    "\n",
    "• Fitting (Training) the model with specified parameters\n",
    "\n",
    "• The model would now run for specified number of parameters and keep updating itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e765dac-6037-4c5b-aef0-c9529ed86ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data = (x_test, y_test), epochs = epochs , callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edffca7-dbd0-44dd-9b8a-836856b0cc44",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION\n",
    "\n",
    "• Plotting a graph between training accuracy and validation accuracy. All of these values were recorded during the training process in `history` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b873fe-b9b8-40bd-bd7c-f385654927ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(callbacks_list[1].best_weights)\n",
    "model.evaluate(x_test, y_test)\n",
    "#mod.save('best_model_5_48.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb514b2-d35f-40e4-bc96-fa27f1091adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.plot(loss, label = 'loss')\n",
    "plt.plot(val_loss, label = 'val_loss')\n",
    "plt.legend()\n",
    "print('minimum loss:', min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7c7a1-97fd-4206-ae1b-00cbad858317",
   "metadata": {},
   "source": [
    "# RESNET-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab199371-1c99-4d8f-8406-49cc88e4285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, AveragePooling2D, BatchNormalization, Dropout, Input, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af7b99-b378-4b05-8f94-7cef6472640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "for layer in res_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = res_model.output\n",
    "model = AveragePooling2D(pool_size = (3,3))(model)\n",
    "model = BatchNormalization(name=\"batch_norm_1\")(model)\n",
    "model = Flatten(name=\"flatten\")(model)\n",
    "model = Dense(512, activation=\"relu\")(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = BatchNormalization(name=\"batch_norm_2\")(model)\n",
    "model = Dense(256, activation=\"relu\")(model)\n",
    "model = Dropout(0.3)(model)\n",
    "model = BatchNormalization(name=\"batch_norm_3\")(model)\n",
    "model = Dense(128, activation=\"relu\")(model)\n",
    "model = Dropout(0.4)(model)\n",
    "model = Dense(1, activation=\"linear\")(model)\n",
    "\n",
    "model = Model(inputs=res_model.input, outputs=model)\n",
    "model.summary()\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(), \n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4c6ec-7625-4259-a723-30b884c504f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
